C:\Users\Christine\PycharmProjects\sexism_detection_bert\venv\Scripts\python.exe C:/Users/Christine/PycharmProjects/sexism_detection_bert/main.py C:\Users\Christine\Downloads\sexism_data.csv text sexist False 
----- Start -----
False
Number of sexist examples: 1809 
 Perc.: 13.271220013205193
Number. of no_sexist examples: 11822 
 Perc.: 86.7287799867948
----- Normalization -----
----- Split data into training, validation and test set -----
No. of training examples: 9542
No. of validation examples: 2862
No. of testing examples: 1227
----- Use distilbert tokenizer to encode data -----
2022-09-08 10:00:15.166540: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-09-08 10:00:15.599430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6615 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1070 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1
----- Initialize base model -----
----- Add classification head -----
Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_layer_norm', 'vocab_projector', 'vocab_transform', 'activation_13']
- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.
If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_ids (InputLayer)         [(None, 512)]        0           []                               
                                                                                                  
 input_attention (InputLayer)   [(None, 512)]        0           []                               
                                                                                                  
 tf_distil_bert_model (TFDistil  TFBaseModelOutput(l  66362880   ['input_ids[0][0]',              
 BertModel)                     ast_hidden_state=(N               'input_attention[0][0]']        
                                one, 512, 768),                                                   
                                 hidden_states=((No                                               
                                ne, 512, 768),                                                    
                                 (None, 512, 768),                                                
                                 (None, 512, 768),                                                
                                 (None, 512, 768),                                                
                                 (None, 512, 768),                                                
                                 (None, 512, 768),                                                
                                 (None, 512, 768)),                                               
                                 attentions=None)                                                 
                                                                                                  
 tf.__operators__.getitem (Slic  (None, 768)         0           ['tf_distil_bert_model[0][7]']   
 ingOpLambda)                                                                                     
                                                                                                  
 dense (Dense)                  (None, 1)            769         ['tf.__operators__.getitem[0][0]'
                                                                 ]                                
                                                                                                  
==================================================================================================
Total params: 66,363,649
Trainable params: 769
Non-trainable params: 66,362,880
__________________________________________________________________________________________________
----- Save model -----
WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000231A544B520>, because it is not built.
WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000231C5CDCCD0>, because it is not built.
WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000231C6CF7430>, because it is not built.
WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000231C6D0FB50>, because it is not built.
WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000231C6CF42B0>, because it is not built.
WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000231C6D079D0>, because it is not built.
WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, transformer_layer_call_fn, transformer_layer_call_and_return_conditional_losses, LayerNorm_layer_call_fn while saving (showing 5 of 164). These functions will not be directly callable after loading.
----- Start training -----
Epoch 1/10
149/149 - 240s - loss: 0.9041 - accuracy: 0.2649 - f1_m: 0.2279 - precision_m: 0.1344 - recall_m: 0.8290 - val_loss: 0.7379 - val_accuracy: 0.3878 - val_f1_m: 0.2231 - val_precision_m: 0.1368 - val_recall_m: 0.6789 - 240s/epoch - 2s/step
Epoch 2/10
149/149 - 236s - loss: 0.6123 - accuracy: 0.6770 - f1_m: 0.1652 - precision_m: 0.1356 - recall_m: 0.2714 - val_loss: 0.5262 - val_accuracy: 0.8491 - val_f1_m: 0.0479 - val_precision_m: 0.1259 - val_recall_m: 0.0333 - 236s/epoch - 2s/step
Epoch 3/10
149/149 - 236s - loss: 0.4899 - accuracy: 0.8359 - f1_m: 0.0574 - precision_m: 0.1261 - recall_m: 0.0427 - val_loss: 0.4401 - val_accuracy: 0.8679 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - 236s/epoch - 2s/step
Epoch 4/10
149/149 - 236s - loss: 0.4358 - accuracy: 0.8647 - f1_m: 0.0046 - precision_m: 0.0168 - recall_m: 0.0027 - val_loss: 0.4044 - val_accuracy: 0.8679 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - 236s/epoch - 2s/step
Epoch 5/10
149/149 - 238s - loss: 0.4096 - accuracy: 0.8638 - f1_m: 0.0011 - precision_m: 0.0034 - recall_m: 6.7114e-04 - val_loss: 0.3882 - val_accuracy: 0.8679 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - 238s/epoch - 2s/step
Epoch 6/10
149/149 - 238s - loss: 0.3998 - accuracy: 0.8652 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.3790 - val_accuracy: 0.8679 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - 238s/epoch - 2s/step
Epoch 7/10
149/149 - 239s - loss: 0.3909 - accuracy: 0.8665 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.3722 - val_accuracy: 0.8679 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - 239s/epoch - 2s/step
Epoch 8/10
149/149 - 238s - loss: 0.3888 - accuracy: 0.8668 - f1_m: 0.0013 - precision_m: 0.0067 - recall_m: 7.4571e-04 - val_loss: 0.3664 - val_accuracy: 0.8679 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - 238s/epoch - 2s/step
Epoch 9/10
149/149 - 238s - loss: 0.3764 - accuracy: 0.8674 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.3610 - val_accuracy: 0.8679 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - 238s/epoch - 2s/step
Epoch 10/10
149/149 - 239s - loss: 0.3747 - accuracy: 0.8661 - f1_m: 0.0015 - precision_m: 0.0067 - recall_m: 8.3893e-04 - val_loss: 0.3558 - val_accuracy: 0.8679 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - 239s/epoch - 2s/step
Minimum Validation Loss: 0.3558
----- Finish training. Start evalution -----
39/39 [==============================] - 22s 528ms/step
Accuracy:   0.8671556642216789
ROC-AUC:    0.7228942755662161
              precision    recall  f1-score   support

       False       0.87      1.00      0.93      1064
        True       0.00      0.00      0.00       163

    accuracy                           0.87      1227
   macro avg       0.43      0.50      0.46      1227
weighted avg       0.75      0.87      0.81      1227

C:\Users\Christine\PycharmProjects\sexism_detection_bert\venv\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
C:\Users\Christine\PycharmProjects\sexism_detection_bert\venv\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
C:\Users\Christine\PycharmProjects\sexism_detection_bert\venv\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

Process finished with exit code 0
